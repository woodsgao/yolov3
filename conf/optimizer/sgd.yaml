optimizer:
  class_name: torch.optim.SGD
  params:
    lr: 1e-2
    momentum: 0.9
    weight_decay: 0.0005
  scheduler: 
    - class_name: torch.optim.lr_scheduler.CosineAnnealingLR
      params:
        T_max: 10
    - class_name: pytorch_modules.optim.lr_scheduler.WarmupLR
      params:
        steps: 10